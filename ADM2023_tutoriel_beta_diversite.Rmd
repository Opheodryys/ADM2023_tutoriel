---
title: "R Notebook"
output: github_document
---
```{bash, eval=FALSE}
git config --global user.email "you@example.com"
git config --global user.name "Your Name"
```

1. On commence par charger toutes les librairies nécessaires. On charge également tous les outils en indiquant à R le chemin d'accès.

```{r}
library(phyloseq)
library(ggplot2)
library(dplyr)
devtools::load_all(path="/home/rstudio/ADM2023_tutoriel/course-material-main/R")
```

On commence par créer une variable output_beta qui contient le chemin d'accès vers un fichier. On demande à R de créer une direction vers la variable output_beta portant ce nom si jamais il n'existe pas. L'argument recursive = TRUE signifie qu'on autorise le fichier output_beta à créer des sous-dossiers.

```{r}
output_beta <- here::here("outputs", "beta_diversity")
if (!dir.exists(output_beta)) dir.create(output_beta, recursive = TRUE)
```

On copie le dossier asv-table contenu dans le course-material-main dans le dossier data contenu dans ADM2023_tutoriel.

```{bash}
cp -R course-material-main/data/asv_table ./data/
```

On crée une variable physeq à laquelle on attribue la fonction pour lire le fichier .rds.

```{r}
physeq <- readRDS(here::here("data",
                             "asv_table",
                             "phyloseq_object_alpha_beta_div.rds"))
```


2.

On a deux approches différentes pour le processus de normalisation des librairies. La première consiste à faire un échantillonage pour réduire le nombre d'observation. Cependant, cela revient à réduire l'échantillonage donc cela faire perdre des données. La seconde méthode emploie une analyse de données avec des ratios logarythmiques.


Première méthode :
On regarde combien de séquences on a par échantillon et on les traduit sous forme de tableau pour regarder leur abondance relative.

```{r}
rowSums(physeq@otu_table@.Data)
```

On crée un objet readsumsdf à qui on attribue la fonction data.frame, cela fait un tableau. nreads : nombre de séquences lues. decreasing = TRUE : les séquences sont classées par ordre décroissant d'abondance. sort = 1 : les séquences sont numérotées de 1 au nombre de taxa de physed. type = OTU : met les séquences dans des OTU.

Ensuite, on crée un objet tmp à qui on attribue la fonction data.frame. On applique le même genre de paramètres pour créer un tableau similaire à readsumsdf.

On combine les tableaux obtenus en un seul tableau avec la fonction rbind. Puis on affiche uniquement les séquences les plus abondantes avec la fonction head().

```{r}
readsumsdf <- data.frame(nreads = sort(taxa_sums(physeq), decreasing = TRUE),
                        sorted = 1:ntaxa(physeq),
                        type = "OTUs")

tmp <- data.frame(nreads = sort(sample_sums(physeq), decreasing = TRUE), 
                  sorted = 1:nsamples(physeq),
                  type = "Samples")

readsumsdf <- rbind(readsumsdf, tmp)

head(readsumsdf)
```

On fait un graphique avec la fonction ggplot. On prend readsumsdf et on met en x les attributions et en y le nombres de reads des séquences. geom_bar est le nombre de séquences différentes. ggtitle permet d'afficher un titre choisi. L'échelle en y est en log10. 

```{r}
ggplot(readsumsdf, aes(x = sorted, y = nreads)) +
  geom_bar(stat = "identity") +
  ggtitle("Total number of reads") +
  scale_y_log10() +
  facet_wrap(~type, nrow = 1, scales = "free")
```

On s'assure que l'effort d'échantillonage est le même. On définit un minimum de lecture dans un échantillon.

```{r}
set.seed(10000)
min(rowSums(physeq@otu_table@.Data))
```

On crée une variable physeq_rar pour l'échantillonage soit de 800 lectures par échanillon.

```{r}
physeq_rar <- rarefy_even_depth(physeq, sample.size = 800)
rowSums(physeq_rar@otu_table@.Data)
physeq
physeq_rar
```


Deuxième méthode : nous utilisons des ratios. Pour cela, il faut transformer nos données en ratios, ce qui nous permettra d'utiliser des méthodes statistiques plus fidèles à la réalité. Pour cela, on crée un objet tmp, qui prendra la fonction zCompositions::cmultRepl, avec method = CZM (count zero multiplicative), label = 0 (par défaut), z.warning = 1 utilisé pour supprimer des colonnes ou des lignes incluant un excès de 0 ou de valeurs non observées. On effectue la transformation des données. L'objet physeq_clr_asv prend la fonction apply, utilisée pour appliquer la transformation à chaque ligne de la matrice tmp. La transformation consiste à prendre le log de chaque valeur et à soustraire la moyenne du log des valeurs de la ligne respective. Cela aide à centrer les données et à les rendre appropriées pour certaines analyses statistiques.

```{r}
tmp <- zCompositions::cmultRepl(physeq@otu_table,
                                method = "CZM",
                                label = 0,
                                z.warning = 1)
physeq_clr_asv <- apply(tmp, 1, function(x) log(x) - mean(log(x)))
```

On crée un nouvel objet physeq_clr en lui attribuant physeq. Ensuite, on remplace la table OTU de cet objet par la matrice de données transformées physeq_clr_asv après l'avoir transposée et convertie en une matrice.

```{r}
physeq_clr <- physeq
otu_table(physeq_clr) <- otu_table(t(physeq_clr_asv),
                                   taxa_are_rows = FALSE)
data.frame(physeq_clr@otu_table@.Data[1:5, 1:10])
```


3. On visualise l'abondance relative des organismes à des rangs taxonomiques spécifiques. On agglomère les données au niveau de la famille puis on transforme en abondance relative via la fonction transform_sample_counts. On filtre les taxons à faible abondance et on trie le bloc de données par ordre alphabétique par phylum.

```{r}
physeq_phylum <- physeq_rar %>%
  tax_glom(taxrank = "Family") %>%                    
  transform_sample_counts(function(x) {x/sum(x)} ) %>%
  psmelt() %>%                                       
  filter(Abundance > 0.02) %>%                        
  arrange(Family)                                      

head(physeq_phylum)
```

On visualise la répartition hiérarchique des phylums grâce à la fonction treemap::treemap. fontside.labels permet de donner la taille des étiquettes. fontcolor.labels permet de donner la couleur des étiquettes. fontface.labels permet de définir une police aux étiquettes ainsi que normal, gra, italique. align.labels permet de choisir l'alignement et la position des étiquettes. overlap.labels permet de déterminer le chevauchement des étiquettes (ici, la valeur par défaut 0,5 signifie que les étiquettes de niveau inférieur sont imprimées si les autres étiquettes ne se chevauchent pas sur plus de 0,5 fois leur taille de zone). inflate.labels permet d'obtenir des étiquettes plus grandes si le rectangle les contenant est grand. border.col permet de définir la couleur des bordures de séparations.

```{r}
treemap::treemap(physeq_phylum, index=c("Class", "Family"), vSize="Abundance", type="index",
        fontsize.labels=c(15,12),                
        fontcolor.labels=c("white","black"),    
        fontface.labels=c(2,1),                 
        align.labels=list(
          c("center", "center"), 
          c("left", "bottom")),                 
        overlap.labels=0.5,                     
        inflate.labels=F, 
        border.col=c("black","white"),          
        border.lwds=c(4,2),
        fontsize.title=12
)
```

On attribue à tmp la fonction transform_sample_counts qui transforme les dénombrements d'échantillons dans une abondance taxonomique. Le dénombrement pour chaque échantillon sera transformé individuellement. La fonction ggplot permet de visualiser l'objet tmp précédemment réalisé.

```{r}
tmp <- transform_sample_counts(physeq,function(x) {x/sum(x)} ) %>%
  psmelt() %>%
  group_by(Family, Class) %>%
  summarise(abundance = sum(Abundance)) %>%
  na.omit()

ggplot(tmp,aes(area=abundance,label=Family,fill=Class,subgroup=Class))+
  treemapify::geom_treemap()+
  treemapify::geom_treemap_subgroup_border() +
  treemapify::geom_treemap_subgroup_text(place = "centre",
                                         grow = T,
                                         alpha = 0.5,
                                         colour = "black",
                                         fontface = "italic",
                                         min.size = 0) +
  treemapify::geom_treemap_text(colour = "white",
                                place = "topleft",
                                reflow = TRUE)+
  theme(legend.position="none")
```

Nous pouvons ensuite sauvegarder notre figure dans le dossier output_beta.

```{r}
ggsave(here::here(output_beta,"treemap_treemapify.pdf"))
```

On reproduit les mêmes étapes avec notre table de composition en ASV (physeq_phylum).

```{r}
ggplot(physeq_phylum, aes(x = Sample, y = Abundance, fill = Family)) + 
  geom_bar(stat = "identity") +
  ylab("Relative Abundance (Family > 2%)") +
  scale_y_continuous(expand = c(0,0)) + 
  ggtitle("Community composition") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 45, size = 10,
                                   hjust = 0.5, vjust = 0.8),
        axis.ticks.x = element_blank(),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank())  
```

```{r}
ggsave(here::here(output_beta, "asv_composition.pdf"))
```


4. Ensuite, on calcule une matrice de distance grâce à l'indice de Jaccard. La distance de Jaccard est utilisée pour mesurer la similarité / dissimilarité de deux échantillons. Binary = TRUE signifie que les données seront lues comme absentes ou présentes (avec des 0 et des 1 dans la matrice respectivement). Cependant, en faisant cela, on risque des valeurs négatives donc on effectue la racine carrée de la matrice. Cela permet la préparation de la matrice de distance à la PCoA (analyse en coordonnées principales).

```{r}
physeq_rar_jaccard <- phyloseq::distance(physeq_rar,
                                         method = "jaccard",
                                         binary = TRUE)
physeq_rar_jaccard <- sqrt(physeq_rar_jaccard)
```


Phylogénétique compositionnelle (unifrac non pondéré) : on vérifie si l'arbre est bien enraciné et on calcule les distances Unifrac. unifracs est une liste contenant 5 matrices de distance correspondant à l'UniFrac pondéré (d_1), non pondéré (d_UW), ajusté à la variance (d_VAW), au GUniFrac avec alpha = 0 et alpha = 0,5. GUniFrac permet de calculer la matrice de distance unifracs. Elle permet de calculer les distances UniFrac généralisées pour mesurer la dissemblance entre les communautés microbiennes. Il prend en entrée le tableau OTU, l'arbre phylogénétique et un vecteur de valeurs alpha (0, 0,5, 1) pour pondérer les distances UniFrac. 

```{r}
ape::is.rooted(physeq_rar@phy_tree)
unifracs <- GUniFrac::GUniFrac(physeq_rar@otu_table@.Data, physeq_rar@phy_tree, alpha=c(0, 0.5, 1))$unifracs
physeq_rar_du <- unifracs[, , "d_UW"]
```


L'objet tmp prend les valeurs normalisées de chaque échantillon. La fonction transform_sample_counts prend chaque décompte d'un échantillon et le divise par la somme des décomptes de cet échantillon. Cela nous permet de calculer la dissimilarité de Bray-Curtis qui permet de mesurer la dissimilarité entre des échantillons grâce à leur composition et leur abondance en espèces. La fonction phyloseq::distance permet de calculer la matrice de distance et (bray = méthode de calcul).

```{r}
tmp <- transform_sample_counts(physeq,function(x) {x/sum(x)} )
physeq_rar_bray <- phyloseq::distance(tmp, method = "bray")
```

```{r}
physeq_rar_dw <- unifracs[, , "d_1"] 
```


On peut calculer ces distances directement dans phyloseq en utilisant la fonction dist.cal. Ici, on va faire une boucle qui parcourt chaque méthode de distance. 

```{r}
dist_methods <- unlist(distanceMethodList)
data.frame(position = seq_along(dist_methods),
           dist_methods)
dist_methods <- dist_methods[c(1, 2, 10, 8)]
dist_methods
```


On calcule la matrice de distance en utilisant la méthode de distance actuelle, qu'on attribue ensuite à l'objet iDist. On fait l'ordination PCoA grâce à cette matrice, et on l'attribue à iMDS. À partir de cela, on peut tracer l'ordination qu'on attribue à p puis on la colorie via l'attribu Geo. On n'oublie pas le titre du tracé qui indique la méthode de distance utilisée. On enregistre chaque tracé dans une liste  "plist" qui sera nommé par le nom de la méthode de distance utilisée.


```{r}
plist <- vector("list")

for(i in dist_methods){
  iDist <- phyloseq::distance(physeq_rar, method = i)
  iMDS <- ordinate(physeq_rar, "MDS", distance = iDist)
  p <- NULL
  p <- plot_ordination(physeq_rar, iMDS, color= "Geo")
  p <- p + ggtitle(paste("MDS using distance method ", i, sep=""))
  plist[[i]] = p 
}
```

On combine les résulats...

```{r}
df <- plyr::ldply(plist, function(x) x$data)
head(df)
```


...puis on change le bloc de données pour donner à la première colonne le nom de distance. On utilise df comme source de donnés, ce qui nous permet de faire le plot. La variable aes permet de spécifier l'esthétique du plot, avec toujours GEO en couleur. On peut ajouter des points au tracé, d'une taille de 3 et d'une transparence de 0.5 qui permet de créer un nuage de point. On va utiliser le thème noir et blanc (theme_bw) puis créer des graphiques de plus petites tailles basés sur la variable distance, sachant que chaque graphique aura sa propre échelle (scales=free). On n'oublie pas le titre du plot.

```{r}
names(df)[1] <- "distance"

ggplot(df, aes(Axis.1, Axis.2, color = Geo)) +
  geom_point(size=3, alpha=0.5) +
  theme_bw() +
  facet_wrap(~distance, scales="free") +
  ggtitle("PCoA (MDS) on various distance metrics")
```


5. On peut maintenant faire le regroupement hiérarchique. On va se baser sur la distance d'Aitchison. D'abord, on va créer un objet qui va accueillir le calcul de la matrice de distance, avec la méthode euclidienne.

```{r}
physeq_clr_dist <- phyloseq::distance(physeq_clr, method = "euclidean")
```


On veut effectuer un regroupement hiérarchique ascendant sur la matrice de distance. hclust permet de calculer une structure hiérarchique de clusters sous forme de dendrogrammes (arbres binaires où les feuilles représentent les observations individuelles et les nœuds internes représentent les groupes ou clusters). Ici, chaque ligne représente une méthode particulière : simple agrégation, agrégation complète, arthimétique ou par parties. par(mfrow=) permet d'obtenir 2x2 graphiques.

```{r}
spe_single <- hclust(physeq_clr_dist, method = "single")
spe_complete <- hclust(physeq_clr_dist, method = "complete")
spe_upgma <- hclust(physeq_clr_dist, method = "average")
spe_ward <- hclust(physeq_clr_dist, method = "ward.D")

par(mfrow = c(2, 2))
plot(spe_single, main = "single")
plot(spe_complete, main = "complete")
plot(spe_upgma, main = "UPGMA")
plot(spe_ward, main = "ward")
```


Ensuite, on fait une matrice cophénétique (matrice représentant les distances cophénétiques entre toutes les paires d'objets). Une corrélation r de Pearson, appelée corrélation cophénétique dans ce contexte, peut être calculée entre la matrice de dissimilarité originale et la matrice cophénétique. La méthode présentant la corrélation cophénétique la plus élevée peut être considérée comme celle qui a produit le meilleur modèle de regroupement pour la matrice de distance. On calcule la matrice cophénétique et la corrélation des quatre résultats de clustering présentés ci-dessus, au moyen de la fonction cophenetic() du package stats.

```{r}
spe_single_coph <- cophenetic(spe_single)
cor(physeq_clr_dist, spe_single_coph)
spe_complete_coph <- cophenetic(spe_complete)
cor(physeq_clr_dist, spe_complete_coph)
spe_upgma_coph <- cophenetic(spe_upgma)
cor(physeq_clr_dist, spe_upgma_coph)
spe_ward_coph <- cophenetic(spe_ward)
cor(physeq_clr_dist, spe_ward_coph)
```


Pour illustrer la relation entre une matrice de distance et un ensemble de matrices cophénétiques, on peut traçer les distances originales par rapport aux distances cophénétiques.

```{r}
plot_coph_cor <- function(cophenetic_distance, hclust_type){
  cor_res <- round(cor(physeq_clr_dist, cophenetic_distance),3)
  plot(x = physeq_clr_dist,
     y = cophenetic_distance,
     xlab = "Aitchison distance",
     ylab = "Cophenetic distance",
     xlim = c(10, 35), ylim = c(10, 35),
     main = c(hclust_type, paste("Cophenetic correlation ", cor_res)))
  abline(0, 1)
}

par(mfrow=c(2,2))

plot_coph_cor(cophenetic_distance = spe_complete_coph,
              hclust_type = "Single linkage")

plot_coph_cor(cophenetic_distance = spe_complete_coph,
              hclust_type = "Complete linkage")

plot_coph_cor(cophenetic_distance = spe_upgma_coph,
              hclust_type = "Average linkage")

plot_coph_cor(cophenetic_distance = spe_ward_coph,
              hclust_type = "Ward linkage")
```


Pour interpréter et comparer les résultats du clustering, il faut des clusters interprétables. Les valeurs du niveau de fusion d'un dendrogramme sont les valeurs de dissimilarité où se produit une fusion entre deux branches d'un dendrogramme. Tracer les valeurs du niveau de fusion peut aider à définir les niveaux de coupe.

```{r}
par(mfrow = c(1, 1))

plot(x = spe_upgma$height,
     y = phyloseq::nsamples(physeq_clr):2,
     type = "S",
     main = "Fusion levels - Aitchison - Average",
     ylab = "k (number of cluster)",
     xlab = "h (node height)")

text(x = spe_upgma$height,
     y = phyloseq::nsamples(physeq_clr):2,
     labels = phyloseq::nsamples(physeq_clr):2,
     col = "red",
     cex = 0.8)
```


On installe le package NbClust qui calculera, avec un seul appel de fonction, 24 indices pour confirmer le bon nombre de clusters dans l'ensemble de données. NbClust confirme l'identification de deux groupes d'échantillons. Nous revenons sur le dendrogramme et le découpons aux distances correspondantes.

```{r}
install.packages("NbClust", lib = ".")
library("NbClust", lib.loc = ".")
nclust <- nb_clust_all(data = t(physeq_clr_asv), seed = 1000)
```


On découpe le dendrogramme créé par clustering hiérarchique (méthode de liaison UPGMA) en groupes k, puis on examine la composition de ces groupes à l'aide de la fonction table.

```{r}
k <- 2
spe_upgma_clust <- cutree(tree = spe_upgma, k = k)
table(spe_upgma_clust)
spe_upgma_clust2 <- data.frame(UPGMA_clusters = spe_upgma_clust)
```

On trace ensuite le dendrogramme avec les groupes.

```{r}
plot(spe_upgma,
     hang = -1,
     ylab = "Height",
     main="Aitchison distance - UPGMA")

rect.hclust(spe_upgma,
            k = k,
            border = 2:6,
            cluster = spe_upgma_clust)

legend("topright",
       paste("Cluster", 1:k),
       pch = 22,
       col = 2:(k + 1),
       bty = "n")
```


Il existe plusieurs façons de mesurer la robustesse d’un algorithme de clustering. Trois mesures couramment utilisées sont l'indice Dunn (rapport de la plus petite distance inter-cluster à la plus grande distance intra-cluster), l'indice Davis-Bouldin et l'indice Silhoutte. Un DI élevé signifie un meilleur regroupement car les observations de chaque cluster sont plus rapprochées. on utilise cluster.stats() pour calculer l'index Dunn. 

```{r}
cs <- fpc::cluster.stats(d = physeq_clr_dist,
                         clustering = spe_upgma_clust)

cs$dunn
```

L'indice de Dunn est élevé, ce qui indique un bon regroupement des échantillons. Maintenant que nous avons identifié deux groupes d’échantillons en fonction de la composition de leur communauté microbienne, nous souhaiterons peut-être examiner quels clades microbiens ou ASV sont enrichis dans chacun des groupes.

On va combiner le Z-score et le clustering. Pour cela, on normalise les valeurs (on centre autour de la moyenne et on réduit). C'est la comparaison d'une valeur observée d'un échantillon à la moyenne de la population. Elle répond donc à la question , à quelle distance de la moyenne de la population se trouve un score pour un échantillon donné. Les scores sont donnés en SD par rapport à la moyenne de la population.


On transforme les comptages de chaque échantillon en pourcentage (transform_sample_counts). Ensuite, on calcule la somme des comptages pour chaque taxon (taxa_sums). On les trie dans l'ordre décroissant et on ne prend que les 30 plus abondants. On crée un objet selection30 qui prend les 30 taxons les plus abondants.

```{r}
pourcentS <- phyloseq::transform_sample_counts(physeq_rar, function(x) x/sum(x) * 100)
mytop30 <- names(sort(phyloseq::taxa_sums(pourcentS), TRUE)[1:30])
selection30 <- phyloseq::prune_taxa(mytop30, pourcentS)
selection30
```


On extrait la table des ASV de l'objet selection30, puis on extrait les données associées qu'on stocke dans l'objet selection30_sample. 
```{r}
selection30_asv <- phyloseq::otu_table(selection30)
selection30_sample <- phyloseq::sample_data(selection30)
rownames(selection30_asv)
```


On crée un nouvel objet qui prend comme valeur la concaténation des colonnes SampName et Description avec _ comme séparateur. Ensuite, l'objet heat prend comme valeur la transposition de la table ASV (échange des lignes par les colonnes) qui a centré puis réduit les valeurs. La matrice heat est ensuite convertie en data.frame. On affiche les 6 premières lignes avec la fonction head.

```{r}
sample_new_names <- paste(selection30_sample$SampName,
                          selection30_sample$Description,
                          sep = "_")

heat <- t(base::scale(selection30_asv))
head(data.frame(heat))
```


On visualise les données sous la forme de carte thermique (fonction Heatmap). Ainsi, on visualise la matrice heat, on ajuste la taille de la police des noms d'échantillons puis on désactive le clustering pour garder l'ordre original des colonnes. On personnalise la légende de la carte thermique : verticale, avec Z-scores en titre, la largeur et la hauteur de 0.5 cm et 3 cm respectivement.

```{r}
ComplexHeatmap::Heatmap(
  heat,
  row_names_gp = grid::gpar(fontsize = 6),
  cluster_columns = FALSE,
  heatmap_legend_param = list(direction = "vertical",
                              title = "Z-scores", 
                              grid_width = unit(0.5, "cm"),
                              legend_height = unit(3, "cm"))
)
```


On extrait la table de selection30 à l'aide de tax_table. On stocke les variables dans l'objet taxon. On change le nom des colonnes en combinant les noms de lignes de taxon, les infos du phylum et les infos de la famille, qui sont séparés par des _. Puis on remplace les noms de colonnes actuels de la table selection30_asv par les nouveaux noms de myname.

```{r}
taxon <- phyloseq::tax_table(selection30) |>
  as.data.frame()
myname <- paste(rownames(taxon), taxon$Phylum, taxon$Family, sep="_")
colnames(selection30_asv) <- myname
```


On prend la matrice selection30_asv qu'on centre-réduit et qu'on transpose dans heat. On crée un objet my_top_annotation qui ajoute des infos supplémentaires au-dessus de la carte thermique. On la visualise avec des paramètres personnalisés (taille de police,...).

```{r}
heat <- t(scale(selection30_asv))

my_top_annotation <- ComplexHeatmap::anno_block(gp = grid::gpar(fill =c(3,4)),
                                               labels = c(1, 2),
                                               labels_gp = grid::gpar(col = "white",
                                                                      fontsize = 10))

ComplexHeatmap::Heatmap(
  heat,
  row_names_gp = grid::gpar(fontsize = 6),
  cluster_columns =TRUE,
  heatmap_legend_param = list(direction = "vertical",
   title ="Z-scores",
   grid_width = unit(0.5, "cm"),
   legend_height = unit(4, "cm")),
  top_annotation = ComplexHeatmap::HeatmapAnnotation(foo = my_top_annotation),
  column_km = 2,
  column_names_gp= grid::gpar(fontsize = 6)
  )
```


Un boxplot est généré pour chaque ligne de selection30_asv montrant la distribution des abondances. Ces boxplots sont affichés comme une annotation à gauche de la carte thermique principale (my_box_plot_left_anno). De la même manière, on ajoute des informations supplémentaires en haut (my_top_anno). Ensuite, on visualise les donnés sous la forme de carte thermique avec toutes les informations précedemment demandées.

```{r}
boxplot <- ComplexHeatmap::anno_boxplot(t(selection30_asv), 
                                        which = "row",
                                        gp = grid::gpar(fill = "turquoise3"))

my_boxplot_left_anno <- ComplexHeatmap::HeatmapAnnotation(Abund = boxplot,
                                                          which = "row",
                                                          width = unit(3, "cm"))

my_top_anno <- ComplexHeatmap::anno_block(gp = grid::gpar(fill = c(3, 6)),
                                          labels = c("South", "North"),
                                          labels_gp = grid::gpar(col = "white",
                                                                fontsize = 10))

my_top_anno <- ComplexHeatmap::HeatmapAnnotation(foo = my_top_anno)

ComplexHeatmap::Heatmap(
  heat,
  row_names_gp = grid::gpar(fontsize = 7),
  left_annotation = my_boxplot_left_anno, 
  heatmap_legend_param = list(direction = "vertical",
                              title ="Z-scores",
                              grid_width = unit(0.5, "cm"),
                              legend_height = unit(3, "cm")),
  top_annotation = my_top_anno,
  column_km = 2,
  cluster_columns = TRUE,
  column_dend_side = "bottom",
  column_names_gp = grid::gpar(fontsize = 7)
  )
```


6.
Analyse en composante principale (PCoA) : permet d'avoir un aperçu des relations entre les objets et les variables. On utilise là aussi la distance de Aitchinson. On commence par extraire la table de physeq_clr pour la transformer en data frame. L'objet ASVname prend la concaténation des noms de lignes actuels + famille et genre pour chaque taxon. Cela permet de renommer les lignes de physeq_clr_asv. La PCoA est réalisée sur physeq_clr_asv, les données associées à chaque échantillon de physeq_clr sont intégrées. On visualise les résulats par un screeplot, ce qui permet de déterminer le nombre de composantes à considérer.

```{r}
tax_CLR <-  as.data.frame(tax_table(physeq_clr))
ASVname <- paste(rownames(tax_CLR), tax_CLR$Family, tax_CLR$Genus,sep="_")
rownames(physeq_clr_asv) <- ASVname
p <- PCAtools::pca(physeq_clr_asv,
                   metadata = data.frame(sample_data(physeq_clr)))
PCAtools::screeplot(p, axisLabSize = 18, titleLabSize = 22)
```


On détermine le nombre optimal de composantes principales à retenir. On fait un test de Horn (parallelPCA) qui détermine le nombre de composantes à conversver en comparant la variance de chaque composante principlae à celle obtenue à partir de jeux de donnés aléatoires. On extrait ce nombre avec horn$n. On fait un test de Elbow qui identifie le point où l'ajout de composantes supplémentaires n'est pas significatif (on atteint donc la stabilisation de la variance). On affiche ensuite cet indice.

```{r}
horn <- PCAtools::parallelPCA(physeq_clr_asv)
horn$n
elbow <- PCAtools::findElbowPoint(p$variance)
elbow
```


On visualise les résultats obtenus. La fonction biplot affcihe les scores des échantillons et les vecteurs de chargement des variables. Les points représentant les échantillons seront étiquettés avec les noms des échantillons contenus dans p$meta.... Encore une fois, on applique le code couleur Geo. La taille des points est de 5, on trace des axes de référence avec hline et vline. La légende est plaxée à droite du biplot.

```{r}
PCAtools::biplot(
  p,
  lab = p$metadata$SampName,
  colby = "Geo",
  pointSize = 5,
  hline = 0, vline = 0,
  legendPosition = "right"
)
```


On fait la même chose mais en ajoutant des paramètres supplémentaires. On ajoute les vecteurs de chargements (donnent une indication de l'importance de la direction de chaque variable dans l'espace des CP). La longueur des flèches est augmentée de 50%. La taille des étiquettes pour le noms des vecteurs de chargement est de 3 et on les colore en rouge. On n'affiche que les 3 vecteurs de chargements les plus importants. Puis, on étiquette les échantillons grâce à leur valeur de X.SampleID. On utilise encore la coloration Geo, des lignes vline et hline et la légende à droite.

```{r}
PCAtools::biplot(
  p, 
  showLoadings = TRUE,
  lengthLoadingsArrowsFactor = 1.5,
  sizeLoadingsNames = 3,
  colLoadingsNames = 'red4',
  ntopLoadings = 3,
  lab = p$metadata$X.SampleID,
  colby = "Geo",
  hline = 0, vline = 0,
  legendPosition = "right"
)
```


On visualise les corrélations entre les principales composantes d'une PCoA et certains variables environnementales ou donnés. components : composantes définies par les résultats du test de Horn. metavars : liste des variables environnementales pour lesquelles les corrélations seront calculées. On utilise plein de couleurs. On ajuste la taille et le style de la police des valeurs de corrélation ainsi que la position des étiquettes des axes. On utilise la corrélation de Spearman. On utilise des symboles pour indiquer la significativité des corrélations.

```{r}
PCAtools::eigencorplot(
  p,
  components = PCAtools::getComponents(p, 1:horn$n),
  metavars = c('SiOH4','NO2','NO3','NH4','PO4',
              'NT','PT','Chla',"T", "S", "Sigma_t"),
  col = c('white', 'cornsilk1', 'gold',
          'forestgreen', 'darkgreen'),
  cexCorval = 1.2,
  fontCorval = 2,
  posLab = "all",
  rotLabX = 45,
  scale = TRUE,
  main = bquote(PC ~ Spearman ~ r^2 ~ environmental ~ correlates),
  plotRsquared = TRUE,
  corFUN = "spearman",
  corUSE = "pairwise.complete.obs",
  corMultipleTestCorrection = 'BH',
  signifSymbols = c("****", "***", "**", "*", ""),
  signifCutpoints = c(0, 0.0001, 0.001, 0.01, 0.05, 1)
)
```


L'analyse PCoA est réalisée sur les distances de Bray-Curtis à partir de physeq_rar_bray. Les coordonnées des deux premiers axes sont extraites et stockées dans pcoa_coord. Le data frame hull contient les coordonnées PCoA et les données associées. On donne deux couleurs pour les catégories North et South. On crée les enveloppes convexes avec le package dplyr. On affiche les premières lignes de hull_data pour vérifier sa structure.

```{r}
pcoa_asv <- ape::pcoa(physeq_rar_bray)
pcoa_coord <- pcoa_asv$vectors[, 1:2]
hull <- data.frame("Axis.1" = pcoa_coord[, 1],
                   "Axis.2" = pcoa_coord[, 2],
                   "sample" = as.data.frame(sample_data(physeq_rar@sam_data)))

hull_col <- c("#a65628","#1919ff")
names(hull_col) <- c("North","South")

hull_data <- hull %>%
  dplyr::group_by(sample.Geo) %>%
  dplyr::slice(chull(Axis.1,Axis.2)) %>%
  dplyr::mutate(color = hull_col[sample.Geo])

head(hull_data)
```


On visualise les résultats de la PCoA sous forme de graphique. Il montre comment les échantillons se répartissent dans l'espace bidimensionnel des deux premières composantes principales et comment ils se regroupent en fonction des catégories "North" et "South". Les enveloppes convexes aident à visualiser la distribution globale de chaque catégorie dans cet espace.

```{r}
ggplot(data = hull, aes(x = Axis.1, y = Axis.2)) +
  geom_hline(yintercept = 0, colour = "lightgrey", linetype = 2) +
  geom_vline(xintercept = 0, colour = "lightgrey", linetype = 2) +
  geom_polygon(data = hull_data,
               aes(group = sample.Geo,
                   fill = sample.Geo),
               alpha = 0.3) + # add the convex hulls)
  scale_fill_manual(values = c("Darkgrey", "#1919ff")) +
  geom_point(data = hull,
             aes(color = sample.Geo,
                 size = sample.S),
             alpha = 0.7) +
  scale_color_manual(values = c("Darkgrey", "#1919ff")) +
  xlab(paste("PCo1 (", round(pcoa_asv$values$Relative_eig[1]*100, 1), "%)")) +
  ylab(paste("PCo2 (", round(pcoa_asv$values$Relative_eig[2]*100, 1), "%)")) +
  theme_bw() +
  coord_equal() +
  theme(axis.title.x = element_text(size = 14), # remove x-axis labels
        axis.title.y = element_text(size = 14), # remove y-axis labels
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),  #remove major-grid labels
        panel.grid.minor = element_blank(),  #remove minor-grid labels
        plot.background = element_blank())
```


On réalise une analyse NMDS (représente fidèlement les distances entre les objets dans un espace à dimension réduite) sur les distances de physeq_clr_dist en utilisant le package vegan. k=2 : deux dimensions. trymax=100 on tente 100 configurations pour trouver la meilleure, puis les résultats sont stockés dans physeq_clr_nmds. La fonction stressplot permet de visualiser le niveau de stress de l'analyse, avec le niveau de stress associé à cette configuration.

```{r}
physeq_clr_nmds <- vegan::metaMDS(physeq_clr_dist, k=2, trymax=100)
vegan::stressplot(physeq_clr_nmds)
```


On visualise les résultats de l'analyse NMDS pour un ensemble de données. Le graphique affiche les points représentant les échantillons dans un espace bidimensionnel défini par les deux axes principaux de l'NMDS. De plus, il trace des enveloppes convexes (hulls) autour des points associés à des catégories spécifiques (dans ce cas, "North" et "South"), aidant à visualiser la distribution et la séparation de ces catégories dans l'espace NMDS. Le niveau de stress de l'analyse NMDS, qui évalue la qualité de la représentation bidimensionnelle, est également affiché sur le graphique.

```{r}
nmds_coord <- data.frame(physeq_clr_nmds$points)

hull <- data.frame("Axis.1" = nmds_coord[,1],
                   "Axis.2" = nmds_coord[,2],
                   "sample" = as.data.frame(sample_data(physeq_clr@sam_data)))

hull_col <- c("#a65628","#1919ff")
names(hull_col) <- c("North","South")

hull_data <- hull %>%
  dplyr::group_by(sample.Geo) %>%
  dplyr::slice(chull(Axis.1,Axis.2)) %>%
  dplyr::mutate(color = hull_col[sample.Geo])

ggplot(hull,aes(x = Axis.1, y = Axis.2)) +
  geom_hline(yintercept = 0, colour = "lightgrey", linetype = 2) + 
  geom_vline(xintercept = 0, colour = "lightgrey", linetype = 2) +
  geom_polygon(data = hull_data,
               aes(group = sample.Geo,
                   fill = sample.Geo),
               alpha = 0.3) + 
  scale_fill_manual(values = c("Darkgrey", "#1919ff")) +
  geom_point(data = hull,
             aes(color = sample.Geo,
                 size = sample.S),
             alpha = 0.7) +
  scale_color_manual(values = c("Darkgrey", "#1919ff")) +
  geom_text(data = hull_data,
            x = -0, y = -9,
            label = paste("Stress =", round(physeq_clr_nmds$stress, 2)),
            colour = "Black",
            size = 5)  +
  xlab(paste("MDS1")) +
  ylab(paste("MDS2")) +
  theme_bw() +
  coord_equal() +
  theme(axis.title.x = element_text(size=14), 
        axis.title.y = element_text(size=14), 
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),  
        panel.grid.minor = element_blank(),  
        plot.background = element_blank())
```


On évalue la correspondance entre les coordonnées NMDS et les variables environnementales. On extrait les noms des colonnes de hull puis les variables environnementales puis on analyse la correspondance avec envfit. On affiche les résultats (pouvant inclure des stats pour chaque variables environnementale). On fait ensuite un graphique pour les visualiser.

```{r}
data.frame(names(hull))
env <- hull[, 13:23]
ef <- vegan::envfit(physeq_clr_nmds, env, permu = 1000)
ef
```

```{r}
plot(physeq_clr_nmds, type = "t", display = "sites")
plot(ef, p.max = 0.05)
```


7.
On fait un test PERMANOVA pour évaluer si la variable Geo a un effet significatif sur la structure des communautés microbiennes représentée par les distances dans physeq_clr_dist. Il utilise ensuite les résultats de cette analyse pour déterminer si les différences observées entre les groupes définis par la variable Geo sont statistiquement significatives.

```{r}
metadata <- data.frame(sample_data(physeq_clr))
results_permanova <- vegan::adonis2(physeq_clr_dist ~ Geo,
                                    data = metadata,
                                    perm = 1000)
results_permanova
```


On évalue l'homogénéité des dispersions de groupes définis par la variable Geo pour déterminer si la variabilité des distances entre les échantillons au sein des groupes est similaire. Cela est fait avec la fonction betadisper suivie d'une ANOVA. Ensuite, on réalise une analyse PERMANOVA sur les données transformées physeq_clr_asv pour tester si la structure des communautés microbiennes diffère significativement entre les groupes définis par Geo. Après, on identifie et on affiche les 10 ASV les plus contributifs à ces différences, sous forme d'un graphique à barres horizontales.

```{r}
anova(vegan::betadisper(physeq_clr_dist, metadata$Geo))
permanova <- vegan::adonis(t(physeq_clr_asv) ~ Geo,
                            data = metadata,
                            permutations = 1000,
                            method = "euclidean")

coef <- coefficients(permanova)["Geo1",]

top.coef <- coef[rev(order(abs(coef)))[1:10]]

par(mar = c(3, 14, 2, 1))

barplot(sort(top.coef),
        horiz = TRUE,
        las = 1,
        main = "Top taxa",
        cex.names = 0.7)
```

On fait pareil avec le S.

```{r}
permanova_S <- vegan::adonis2(physeq_clr_dist ~ S,
                              data = metadata,
                              perm = 1000)
permanova_S
```

Puis pareil avec le NH4.

```{r}
permanova_NH4 <- vegan::adonis2(physeq_clr_dist ~ NH4,
                                data = metadata,
                                perm = 1000)
permanova_NH4
```

Puis pareil avec le PT.

```{r}
permanova_PT <- vegan::adonis2(physeq_clr_dist ~ PT,
                               data = metadata,
                               perm = 1000)
permanova_PT
```

On regarde ensuite les résultats par rapport à toutes les variables.

```{r}
permanova_all <- vegan::adonis2(physeq_clr_dist ~ SiOH4 + NO2 + NO3 + NH4 + PO4 + NT + PT + Chla + T + S + Sigma_t,
                                by="margin",
                                data=metadata,
                                perm=1000)

permanova_all
```


On calcule la matrice de corrélation de Spearman pour certains colonnes de metadata. On évalue ensuite la significativité de ces corrélations en effectuant des tests stats. On visualise la matrice de corrélation en utilisant un "corrplot", où seules les corrélations significatives sont affichées. Les corrélations non significatives sont laissées en blanc dans le graphique.

```{r}
cor_metadadata <- cor(metadata[, 11:21], method = "spearman")

cor_mtest <- function(mat, ...) {
  mat <- as.matrix(mat)
  n <- ncol(mat)
  p_mat <- matrix(NA, n, n)
  diag(p_mat) <- 0
  for (i in 1:(n - 1)) {
    for (j in (i + 1):n) {
      tmp <- cor.test(mat[, i], mat[, j], method = "spearman", ...)
      p_mat[i, j] <- p_mat[j, i] <- tmp$p.value
    }
  }
  colnames(p_mat) <- rownames(p_mat) <- colnames(mat)
  p_mat
}

p_mat <- cor_mtest(metadata[, 11:21])

corrplot::corrplot(cor_metadadata,
                   type = "upper",
                   order = "hclust",
                   p.mat = p_mat,
                   sig.level = 0.05,
                   insig = "blank")
```


On effectue une analyse PERMANOVA pour évaluer l'effet de plusieurs variables environnementales (S, NO3, NT, Chla, T) sur la structure des communautés microbiennes représentée par les distances dans physeq_clr_dist. L'argument by = "margin" signifie que l'effet de chaque variable est évalué en tenant compte des autres. Les résultats de cette analyse sont ensuite affichés pour déterminer si les différences observées associées à ces variables environnementales sont statistiquement significatives.

```{r}
permanova_cor_pars <- vegan::adonis2(physeq_clr_dist ~ S + NO3 + NT + Chla + T,
                                     by = "margin",
                                     data = metadata,
                                     perm = 1000)
permanova_cor_pars
```


On teste si les différences entre les groupes définis par la variable Geo sont plus grandes que ce que l'on pourrait attendre par hasard, étant donné les distances ou dissimilarités entre les échantillons dans physeq_clr_dist. Si le résultat est significatif, cela suggère que la variable Geo a un effet sur la structure des communautés microbiennes.

```{r}
vegan::anosim(physeq_clr_dist, metadata$Geo, permutations = 1000)
```


8.
On effectue une analyse de la redondance pour explorer les relations entre la structure des communautés microbiennes dans physeq_clr_asv et un ensemble de variables environnementales contenues dans certaines colonnes de metadata. On affiche ensuite un résumé des premiers résultats de cette analyse.

```{r}
spe_rda <- vegan::rda(t(physeq_clr_asv) ~ .,
                      metadata[, 11:21])
head(summary(spe_rda))
```


On calcule et on affiche le coefficient de détermination R2 et R2 ajusté de l'analyse réalisée juste avant. Ces coefficients indiquent la proportion de la variance dans les données de la communauté microbiologique qui est expliquée par les variables environnementales utilisées dans la RDA.

```{r}
R2 <- vegan::RsquareAdj(spe_rda)$r.squared
R2
R2adj <- vegan::RsquareAdj(spe_rda)$adj.r.squared
R2adj
```


On réalise des tests de permutation ANOVA sur les résultats de l'analyse de la redondance pour évaluer la significativité des axes et de l'ensemble du modèle. On effectue d'abord un test sur l'ensemble du modèle RDA, puis un test pour chaque axe de la RDA individuellement. Ces tests utilisent des permutations pour évaluer la significativité.

```{r}
anova(spe_rda, step = 1000)
anova(spe_rda, by = "axis", step = 1000)
```


On calcule les facteurs d'inflation de la variance (VIF) pour évaluer la multicollinéarité entre les variables environnementales utilisées dans la RDA et on réalise une sélection séquentielle de variables (stepwise) en utilisant une méthode orientée vers l'avant (forward) pour déterminer quelles variables environnementales contribuent de manière significative à la structure des communautés microbiennes.

```{r}
vegan::vif.cca(spe_rda)
step_forward <- vegan::ordiR2step(vegan::rda(t(physeq_clr_asv) ~ 1,
                                             data = metadata[, 11:21]),
                                  scope = formula(spe_rda),
                                  direction = "forward",
                                  pstep = 1000)
```


On se concentre ensuite plus particulièrement sur la variable S pour explorer sa relation avec la structure des communautés microbiennes dans physeq_clr_asv. Ensuite, on effectue des tests de permutation ANOVA sur les résultats de cette RDA pour évaluer la significativité de l'ensemble du modèle ainsi que de chaque axe individuellement.

```{r}
spe_rda_pars <- vegan::rda(t(physeq_clr_asv) ~ S, data = metadata[, 11:21])
anova(spe_rda_pars, step = 1000)
anova(spe_rda_pars, step = 1000, by = "axis")
```


On calcule stocke le coefficient de détermination R2 et R2 ajusté pour les résultats de l'Analyse de la Redondance (RDA) basée sur la variable "S". Puis on calcule les facteurs d'inflation de la variance (VIF) pour évaluer la multicollinéarité entre les variables environnementales de l'analyse RDA originale. Enfin, on calcule les VIF pour l'analyse RDA basée uniquement sur la variable "S" pour évaluer la multicollinéarité.

```{r}
R2adj_pars <- vegan::RsquareAdj(spe_rda_pars)$adj.r.squared
vegan::vif.cca(spe_rda)
vegan::vif.cca(spe_rda_pars)
```


On fait un plot qui permet de visualiser la position des échantillons (sites) dans l'espace RDA, distingués par la variable "Geo", les six ASV les plus contributives à la variation observée et l'influence de la salinité sur la structure des communautés microbiennes. Le graphique résultant aide à interpréter comment les échantillons se regroupent en fonction de la variable Geo et à comprendre l'effet des espèces les plus contributives et de la salinité sur cette structure.

```{r}
ii <- summary(spe_rda_pars)

sp <- as.data.frame(ii$species[, 1:2]) * 2
sp_top <- sp[order(abs(sp$RDA1), decreasing = TRUE), ][1:6, ]

st <- as.data.frame(ii$sites[, 1:2])
st <- merge(st,
      metadata["Geo"],
      by = "row.names")

yz <- t(as.data.frame(ii$biplot[, 1:2]))
row.names(yz) <- "Salinity"
yz <- as.data.frame(yz)

eigen_values <- format(100 *ii$cont[[1]][2,], digits=4)

ggplot() +
  geom_point(data = st, size = 4,
             aes(x = RDA1, y = PC1,
                 shape = Geo, fill = Geo)) +
  scale_shape_manual(values = c(21:25)) +
  geom_segment(data = sp_top,
               arrow = arrow(angle = 22.5,
                             length = unit(0.35, "cm"),
                             type = "closed"),
               linetype = 1, size = 0.6, colour = "red",
               aes(x = 0, y = 0, xend = RDA1, yend = PC1)) +
  ggrepel::geom_text_repel(data = sp_top,
                           aes(x = RDA1, y = PC1, label = row.names(sp_top))) +
  geom_segment(data = yz,
               arrow = arrow(angle = 22.5,
                             length = unit(0.35,"cm"),
                             type = "closed"),
               linetype = 1, size = 0.6, colour = "blue",
               aes(x = 0, y = 0, xend = RDA1, yend = PC1)) +
  ggrepel::geom_text_repel(data = yz, aes(RDA1, PC1, label=row.names(yz)))+
  labs(x = paste("RDA 1 (", eigen_values[1], "%)", sep = ""),
       y = paste("PC 1 (", eigen_values[2], "%)", sep = ""))+
  geom_hline(yintercept = 0,linetype = 3,size = 1) + 
  geom_vline(xintercept = 0,linetype = 3,size = 1)+
  guides(shape = guide_legend(title = NULL,
         color = "black"),
         fill = guide_legend(title = NULL))+
  theme_bw() +
  theme(panel.grid = element_blank())
```


On indique à R de copier le dossier beta_diversity dans le /data du menu home.

```{bash}
cp -R /home/rstudio/ADM2023_tutoriel/course-material-main/data/beta_diversity ./data
```


On lit le fichier spatial_distance.rds et on calcule une matrice de distance à partir de cet objet.

```{r}
ANF_km <- readRDS(here::here("data","beta_diversity","spatial_distance.rds"))
ANF_km_dist <- dist(ANF_km)
```


On effectue une analyse de décroissance de la dissimilarité. L'idée est d'examiner comment la dissimilarité écologique (ici basée sur la transformation CLR) entre les échantillons change en fonction de leur distance spatiale. On utilise le modèle exponentiel de décroissance pour ajuster les données. On affiche un graphique de dispersion des distances spatiales par rapport à la dissimilarité. On superpose le modèle de décroissance exponentiel ajusté sur le graphique de dispersion. On met une légende indiquant les paramètres et statistiques du modèle ajusté. L'objectif est de voir si, à mesure que les échantillons sont plus éloignés les uns des autres dans l'espace, ils deviennent également plus dissimilaires écologiquement.

```{r}
ANF_decay_exp <- betapart::decay.model(physeq_clr_dist/100,
                                       ANF_km_dist,
                                       y.type="dissim",
                                       model.type="exp",
                                       perm=100)
plot(ANF_km_dist, physeq_clr_dist/100,
     ylim=c(0, max(physeq_clr_dist/100)),
     xlim=c(0, max(ANF_km_dist)),
     xlab = "Distance (km)", ylab = "Dissimilarity (CLR)")

betapart::plot.decay(ANF_decay_exp, col = "blue",
                     remove.dots = TRUE, add = TRUE)

legend("bottomright",
       paste("exp: (Beta =", round(ANF_decay_exp$second.parameter, 4),
             ", Rsqr =", round(ANF_decay_exp$pseudo.r.squared, 2),
             ", p =", round(ANF_decay_exp$p.value, 2)),
       fill = "blue")
```


On fait une analyse de Mantel régressée par morceaux. On calcule une matrice de distance euclidienne pour les données physeq_clr. On calcule également une matrice de distance pour les distances spatiales ANF_km de la même manière. Puis, on calcule une matrice de distance pour certaines variables environnementales présentes dans metadata. On utilise ensuite ces matrices pour effectuer une analyse de Mantel afin d'évaluer comment la structure des communautés microbiennes (distance physeq_clr) est expliquée par les distances spatiales et les variables environnementales simultanément. L'objectif est de déterminer dans quelle mesure les variables environnementales et spatiales influencent conjointement la structure des communautés microbiennes.

```{r}
physeq_clr_dist_square <- phyloseq::distance(physeq_clr,
                                             method = "euclidean",
                                             diag = TRUE,
                                             upper = TRUE)
ANF_km_dist_square <- dist(ANF_km, diag = TRUE, upper = TRUE)
envdata <- dist(metadata[,11:21], diag = TRUE, upper = TRUE)
ecodist::MRM(physeq_clr_dist_square ~ envdata + ANF_km_dist_square, nperm=1000)
```


On effectue une analyse de Mantel régressée par morceaux (MRM) pour évaluer la relation entre la structure des communautés microbiennes (distance physeq_clr) et les variables environnementales. Puis on réalise une autre analyse MRM pour évaluer la relation entre la structure des communautés microbiennes (distance physeq_clr) et les distances spatiales (ANF_km). Enfin, on utilise la fonction varPart du package modEvA pour effectuer une partition de la variance, afin de décomposer la contribution relative des effets environnementaux et de la limitation de la dispersion (probablement en termes d'influence spatiale) sur la structure des communautés microbiennes. L'objectif est de décomposer l'influence relative des facteurs environnementaux et spatiaux sur la structure des communautés microbiennes.

```{r}
ecodist::MRM(physeq_clr_dist_square ~ envdata, nperm=1000)
ecodist::MRM(physeq_clr_dist_square ~ ANF_km_dist_square, nperm=1000)
modEvA::varPart(A = 0.212, B = 0.238, AB = 0.366,
                A.name = "Environmental",
                B.name = "Dispersal limitation")
```


9.
On réalise une analyse LEfSe sur les données phylogénétiques fournies par physeq. La fonction run_lefse du package microbiomeMarker est utilisée pour identifier les ASV qui sont statistiquement différentes entre les groupes définis par la variable "Geo". La normalisation est faite en utilisant la méthode "Counts Per Million" (CPM). Des seuils spécifiques sont définis pour les tests de Wilcoxon et Kruskal-Wallis. L'analyse est configurée pour identifier des marqueurs dans des groupes multiples et un seuil pour la taille de l'effet est défini. Les résultats de l'analyse LEfSe sont ensuite convertis en une dataframe pour faciliter l'affichage et la manipulation. L'objectif est d'identifier quels microorganismes (ou groupes de microorganismes) sont significativement associés à chacun des groupes définis par la variable "Geo".

```{r}
mm_lefse <- microbiomeMarker::run_lefse(physeq, norm = "CPM",
                                        wilcoxon_cutoff = 0.01,
                                        group = "Geo",
                                        taxa_rank = "none",
                                        kw_cutoff = 0.01,
                                        multigrp_strat = TRUE,
                                        lda_cutoff = 4)

mm_lefse_table <- data.frame(mm_lefse@marker_table)
mm_lefse_table
```


On génère et on affiche deux types de graphiques basés sur les résultats de l'analyse LEfSe réalisée précédemment sur les données phylogénétiques. plot_ef_bar crée un graphique à barres montrant la taille de l'effet (LDA score) pour chaque ASV identifié comme étant significativement différent entre les groupes. Plus la barre est haute (ou basse), plus la différence est marquée. plot_abundance génère un graphique à barres empilées montrant l'abondance relative des microorganismes identifiés comme marqueurs entre les différents groupes définis par la variable "Geo". Enfin, grid.arrange combine et affiche ces deux graphiques côte à côte pour une comparaison visuelle. L'objectif est de visualiser à la fois la taille de l'effet et l'abondance des microorganismes identifiés comme étant significativement différents entre les groupes.

```{r}
p_LDAsc <- microbiomeMarker::plot_ef_bar(mm_lefse)
y_labs <- ggplot_build(p_LDAsc)$layout$panel_params[[1]]$y$get_labels()
p_abd <- microbiomeMarker::plot_abundance(mm_lefse, group = "Geo") +
  scale_y_discrete(limits = y_labs)
gridExtra::grid.arrange(p_LDAsc, p_abd, nrow = 1)
```


On effectue une analyse ANCOM-BC sur les données phylogénétiques fournies par physeq. La fonction run_ancombc_patched est utilisée pour identifier les espèces (ou ASV/OTU) qui sont statistiquement différentes entre les groupes définis par la variable "Geo". Un seuil de p-valeur est défini pour déterminer la significativité statistique. La correction pour les tests multiples est réalisée en utilisant la méthode FDR (False Discovery Rate). Les résultats de l'analyse ANCOM-BC sont ensuite convertis en une dataframe pour faciliter l'affichage et la manipulation. L'objectif est d'identifier quels microorganismes (ou groupes de microorganismes) montrent des abondances significativement différentes entre les groupes définis par la variable "Geo", tout en corrigeant pour les biais potentiels dans l'analyse des données composées comme celles des données microbiennes.

```{r}
mm_ancombc <- run_ancombc_patched(
  physeq,
  group = "Geo",
  taxa_rank = "none",
  pvalue_cutoff = 0.001,
  p_adjust = "fdr"
)

mm_ancombc_table <- data.frame(mm_ancombc@marker_table)
mm_ancombc_table
```


On affiche deux types de graphiques basés sur les résultats de l'analyse ANCOM-BC réalisée précédemment sur les données phylogénétiques. plot_ef_bar crée un graphique à barres qui illustre la taille de l'effet pour chaque microorganisme (ou ASV/OTU) identifié comme étant significativement différent entre les groupes. Les barres indiquent l'importance de chaque différence détectée. plot_abundance produit un graphique à barres empilées montrant l'abondance relative des microorganismes identifiés comme marqueurs entre les différents groupes définis par la variable "Geo". Ensuite, grid.arrange combine et affiche ces deux graphiques côte à côte pour une comparaison visuelle. L'objectif est de visualiser à la fois la taille de l'effet et l'abondance des microorganismes qui ont été identifiés comme étant significativement différents entre les groupes à partir de l'analyse ANCOM-BC.

```{r}
an_ef <- microbiomeMarker::plot_ef_bar(mm_ancombc)
y_labs <- ggplot_build(an_ef)$layout$panel_params[[1]]$y$get_labels()
an_abd <- microbiomeMarker::plot_abundance(mm_ancombc, group = "Geo") +
  scale_y_discrete(limits = y_labs)
gridExtra::grid.arrange(an_ef, an_abd, nrow = 1)
```


On effectue une analyse ALDEx2 (ANalysis of Differential Abundance taking into account the Library sIzE) sur les données phylogénétiques fournies par physeq. La fonction run_aldex du package microbiomeMarker est utilisée pour identifier les ASV qui sont statistiquement différentes entre les groupes définis par la variable "Geo". La normalisation est effectuée en utilisant la méthode "Counts Per Million" (CPM). La correction pour les tests multiples est réalisée en utilisant la méthode FDR (False Discovery Rate). Les résultats de l'analyse ALDEx2 sont ensuite convertis en une dataframe pour faciliter l'affichage et la manipulation. L'objectif est d'identifier quels microorganismes (ou groupes de microorganismes) montrent des abondances significativement différentes entre les groupes définis par la variable "Geo" en utilisant l'approche ALDEx2, qui est spécialement conçue pour traiter les données de séquençage à haut débit.

```{r}
mm_aldex <- microbiomeMarker::run_aldex(physeq, group = "Geo",
                                        norm = "CPM",
                                        taxa_rank = "none",
                                        p_adjust = "fdr")

mm_aldex_table <- data.frame(mm_aldex@marker_table)
mm_aldex_table
```
