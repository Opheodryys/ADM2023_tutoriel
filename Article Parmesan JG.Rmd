---
title: "Article Parmesan"
author: "Justine Gastinel"
date: "2023-11-29"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{bash, eval=FALSE}
git config --global user.email "you@example.com"
git config --global user.name "Your Name"
```

On commence par créer une variable sequencesR1R2 qui contient le chemin d'accès vers un fichier. On demande à R de créer une direction vers la variable sequences portant ce nom si jamais il n'existe pas. L'argument recursive = TRUE signifie qu'on autorise le fichier sequences à créer des sous-dossiers.

```{r}
sequencesR1R2 <- here::here("data", "sequences")
sequencesR1R2
if (!dir.exists(sequencesR1R2)) dir.create(sequencesR1R2, recursive = TRUE)
```

On dit à R d'augmenter le temps avant qu'il arrête tout seul le téléchargement (on lui donne 20 minutes).

```{r}
getOption("timeout")
options(timeout=1200)
```

Cette variable reçoit le chemin dans le fichier refdb.

```{r}
silva_train_set <- file.path(sequencesR1R2, "silva_nr99_v138.1_train_set.fa.gz")

```

```{r}
silva_species_assignment <- file.path(sequencesR1R2,"silva_species_assignment_v138.1.fa.gz")
```

On télécharge ensuite les données sur Zenodo si le fichier de données n'existe pas dans le fichier. Pour la première, on télécharge ce fichier de données dans le bon fichier créé. L'argument quiet = TRUE permet de faire un DL sans afficher la progression du téléchargement. Pareil pour la deuxième.

```{r}
if (!file.exists(silva_train_set)) {
  download.file(
    "https://zenodo.org/record/4587955/files/silva_nr99_v138.1_train_set.fa.gz",
    silva_train_set,
    quiet = TRUE
  )
}


if (!file.exists(silva_species_assignment)) {
  download.file(
    "https://zenodo.org/record/4587955/files/silva_species_assignment_v138.1.fa.gz",
    silva_species_assignment,
    quiet = TRUE
  )
}


```

On fait une nouvelle variable qui donnera le chemin aux données. On crée 2 nouvelles variables qui vont chacune regrouper les séquences possédant R1 dans l'une et R2 dans l'autre.
 
```{r}
chemin_sequences <- here::here("data", "sequences")

seqR1 <- sort(list.files(chemin_sequences, pattern = "_1.fastq.gz", full.names = TRUE))

seqR2 <- sort(list.files(chemin_sequences, pattern = "_2.fastq.gz", full.names = TRUE))
```

On extrait uniquement le nom de l'échantillon. basename retire le chemin pour y accéder pour garder uniquement le nom du fichier. |> permet de faire des chaînes de fonctions sans utiliser de commandes ou de parenthèses. La traduction est tuyau, donc la commande rentre dans le tuyau. strsplit() coupe la chaîne selon le pattern indiqué entre " ". sapply() applique une fonction à chaque élément de la liste ou du vecteur pour le simplifier, ici on sélectionne juste le premier élément de la liste (juste le nom des échantillons).

```{r}
sample_names <- basename(seqR1) |>
  strsplit(split = "_") |>
  sapply(head, 1)
```

D'abord, on liste les noms des fichiers R1.

```{r}
basename(seqR1) |>
  head()
```

La fonction strsplit() permet de séparer chaque nom de fichier à un endroit donné en un vecteur comportant 2 éléments. Le résultat est une liste de vecteurs avec 2 éléments.

```{r}
basename(seqR1) |>
  strsplit(split = "_") |>
  head()
```

Maintenant, on retient uniquement la première partie du nom, soit SxX.

```{r}
basename(seqR1) |>
  strsplit(split = "_") |>
  sapply(head, 1) |>
  head()
```

On fait la même chose avec les séquences R2.

```{r}
sample_names <- basename(seqR2) |>
  strsplit(split = "_") |>
  sapply(head, 1)
```

```{r}
basename(seqR2) |>
  head()
```

```{r}
basename(seqR2) |>
  strsplit(split = "_") |>
  head()
```

```{r}
basename(seqR2) |>
  strsplit(split = "_") |>
  sapply(head, 1) |>
  head()
```

On indique à R l'endroit où doivent se trouver les outils.

```{r, eval=FALSE}
devtools::load_all(path="/home/rstudio/ADM2023_tutoriel/course-material-main/R")
```

On crée une variable graphiques avec le chemin menant aux graphiques. Ainsi, si le fichier n'existe pas, on le fait dans notre répertoire. qualityprofile permet de vérifier la qualité des séquences brutes.

```{r}
graphiques <- here::here("outputs",
                             "dada2",
                             "graphiques")

if (!dir.exists(graphiques)) {
  dir.create(graphiques, recursive = TRUE)
}

qualityprofile(seqR1,
               seqR2,
               file.path(graphiques, "quality_plots.pdf"))
```

On souhaite raccourcir les séquences pour retirer les bases avec le moins bon Qscore. On crée une variable pour diriger R vers les séquences raccourcies. Pareil, si la direction n'existe pas, on crée une direction vers ce fichier.

```{r}
seq_trimmed <- here::here(
  "outputs",
  "dada2",
  "trimmed"
)

if (!dir.exists(seq_trimmed)) dir.create(seq_trimmed, recursive = TRUE)
```

On attribue à l'amorce directe et reverse leur séquence respective. 

```{r}
primer_R1  <- "CCTACGGGNBGCASCAG"
primer_R2  <- "GACTACNVGGGTATCTAATCC"
```

On lit les 10 premières (R1) et 10 dernières (R2) séquences en format fastq.

```{r}
Biostrings::readDNAStringSet(
  seqR1[1],
  format = "fastq",
  nrec = 10
)
```

```{r}
Biostrings::readDNAStringSet(
  seqR2[1],
  format = "fastq",
  nrec = 10
)
```

On copie les informations du dossier bash dans un nouveau dossier bash dans le ADM2023_tutoriel.

```{bash}
pwd
cp -R /home/rstudio/ADM2023_tutoriel/course-material-main/bash .
```

La variable primer_log prend la fonction primer_trim comme objet. On retire les amorces par cette fonction. forward et reverse correspondent aux séquences directes et complémentaires. primer_fwd et primer_rev correspondent aux amorces. output_dir permet de noter toutes les séquences raccourcies. Les séquences raccourcies doivent faire plus de 200 pb.

```{r}
(primer_log <- primer_trim(
  forward_files = seqR1,
  reverse_files = seqR2,
  primer_fwd = primer_R1,
  primer_rev = primer_R2,
  output_dir = seq_trimmed,
  min_size = 200
))
```

On extrait les séquences raccourcies pour les séquences directes et complémentaires en demandant tous les noms.

```{r}
nopR1 <- sort(list.files(seq_trimmed, pattern ="_1", full.names = TRUE))
nopR2 <- sort(list.files(seq_trimmed, pattern ="_2", full.names = TRUE))
```

On crée un dossier menant aux séquences filtrées ainsi que les variables qui serviront ensuite.

```{r}
seq_filtrees <- here::here("outputs", "dada2", "filtered")
if (!dir.exists(seq_filtrees)) dir.create(seq_filtrees, recursive = TRUE)
```

```{r}
filtR1 <- file.path(seq_filtrees, basename(seqR1))
filtR2 <- file.path(seq_filtrees, basename(seqR2))
```

```{r}
names(filtR1) <- sample_names
names(filtR2) <- sample_names
```

On extrait uniquement les séquences sélectionnées par dada2. On entre les variables correspondant aux séquences filtrées raccourcies directes et indecteres. Dada2 ne prend pas en compte les séquences plus petites que 150nt. Il faut que chaque R1 ait une séquence R2 associée. Il ne faut pas d'ambiguités (argument maxN). MaxEE donne le nombre d'erreurs maximales admises, basée sur le calcul du Qscore. truncQ retire les séquences inférieure à un Qscore donné (2 = QScore de 20)

```{r}
(out <- dada2::filterAndTrim(
  fwd = nopR1,
  filt = filtR1,
  rev = nopR2,
  filt.rev = filtR2,
  minLen = 150,
  matchIDs = TRUE,
  maxN = 0,
  maxEE = c(3, 3),
  truncQ = 2
))
```

Le taux d'erreur est estimé ensuite. On attribue à un nouvel objet errF et errR la fonction d'estimation d'erreurs de dada2, avec comme argument les séquences directes filtrées tirées aléatoirement parmi toutes les séquences filtrées totales. On applique la même fonction pour les séquences reverses. On applique ensuite la fonction dada2::plotErrors pour faire un graphique des erreurs estimées de chaque transition de base.

```{r}
errR1 <- dada2::learnErrors(filtR1,
                           randomize = TRUE,
                           multithread = TRUE)

errR2 <- dada2::learnErrors(filtR2,
                           randomize = TRUE,
                           multithread = TRUE)
dada2::plotErrors(errR1, nominalQ=TRUE)
```

On retire ensuite les séquences lues en double. Pour chaque séquence unique, on compte le nombre de lectures.

```{r}
derepR1 <- dada2::derepFastq(filtR1, verbose = TRUE)
derepR2 <- dada2::derepFastq(filtR2, verbose = TRUE)
```

Ensuite, on fait correspondre l'erreur estimée sur les séquences uniques. 

```{r}
dadaR1 <- dada2::dada(derepR1, err = errR1, multithread = TRUE)
dadaR2 <- dada2::dada(derepR2, err = errR2, multithread = TRUE)
```

Cette fonction permet d'associer les séquences entre elles sans mismatch (erreur d'association des bases). L'argument verbose permet d'avoir un résumer de la fonction.


```{r}
mergers <- dada2::mergePairs(
  dadaF = dadaR1,
  derepF = derepR1,
  dadaR = dadaR2,
  derepR = derepR2,
  maxMismatch = 0,
  verbose = TRUE
)
```

On fabrique une table compilant les séquences associées précedemment, avec le nombre de lecture pour chaque séquence.

```{r}
table <- dada2::makeSequenceTable(mergers)
```

On retire les séquences chimères qui résultent d'un mauvais appariement. Chaque séquence est passée au crible. On a ensuite le résumé.

```{r}
seqtab_nochim <- dada2::removeBimeraDenovo(table,
                                           method = "consensus",
                                           multithread = TRUE,
                                           verbose = TRUE)
```

On associe ensuite une appartenance taxonomique à nos séquences. Cela permettra l'interprétation de nos séquences dans l'environnement. Cette appartenance s'effectue en 2 étapes. D'abord, on utilise l'algorithme de Wang et al pour assigner la taxonomie. On utilise les séquences précedemment obtenues. refFasta donne le chemin vers les séquences.taxLevels attribue le niveau taxonomique. minBoot est le niveau de confiance minimum pour l'aassociation taxonimique.

```{r}
taxonomy <- dada2::assignTaxonomy(
  seqs = seqtab_nochim,
  refFasta = silva_train_set,
  taxLevels = c("Kingdom", "Phylum", "Class",
                "Order", "Family", "Genus",
                "Species"),
  multithread = TRUE,
  minBoot = 60
)
```

Puis on attribue le rang espèces aux ASV qui sont identique à une séquence de référence.

```{r}
taxonomy <- dada2::addSpecies(
  taxonomy,
  silva_species_assignment,
  allowMultiple = FALSE
)
```

On exporte les données sous forme d'objets R, un pour la table d'ASV et une autre pour la taxonomie. On crée le fichier et on indique le chemin à R.

```{r}
export <- here::here("outputs", "dada2", "asv_table")

if (!dir.exists(export)) dir.create(export, recursive = TRUE)

saveRDS(object = seqtab_nochim,
        file = file.path(export, "seqtab_nochim.rds"))

saveRDS(object = taxonomy,
        file = file.path(export, "taxonomy.rds"))
```

On collecte les séquences ASV et on attribue des ID uniques pour chaque séquence, afin que leur nom soit plus court. On renomme les variables en leur attribuant ce nouveau nom.

```{r}
ASV <- colnames(seqtab_nochim)
ndigits <- nchar(length(ASV))
asv_id <- sprintf(paste0("ASV_%0", ndigits, "d"), seq_along(ASV))
row.names(taxonomy) <- colnames(seqtab_nochim) <- names(ASV) <- asv_id
```

Ces nouvelles identités sont collectées dans une nouvelle colonne asv. 

```{r}
taxonomy_export <- df_export(taxonomy, new_rn = "asv")

seqtab_nochim_export <- t(seqtab_nochim)
seqtab_nochim_export <- df_export(seqtab_nochim_export, new_rn = "asv")
```

On exporte ensuite la taxonomie,

```{r}
write.table(taxonomy_export,
            file = file.path(export_folder, "taxonomy.tsv"),
            quote = FALSE,
            sep = "\t",
            row.names = FALSE)
```

puis la table ASV,

```{r}
write.table(seqtab_nochim_export,
            file = file.path(export_folder, "asv_table.tsv"),
            quote = FALSE,
            sep = "\t",
            row.names = FALSE)
```

et les séquences en format FASTA

```{r}
cat(paste0(">", names(ASV), "\n", ASV),
    sep = "\n",
    file = file.path(export_folder, "asv.fasta"))
```

On assemble la table regroupant les statistiques à propos de chaque étape vu ci-dessus.

```{r}
getN <- function(x) sum(dada2::getUniques(x))

log_table <- data.frame(
  input = primer_log$in_reads,
  with_fwd_primer = primer_log$`w/adapters`,
  with_rev_primer = primer_log$`w/adapters2` ,
  with_both_primers = out[, 1],
  filtered = out[, 2],
  denoisedF = sapply(dadaR1, getN),
  denoisedR = sapply(dadaR2, getN),
  merged = sapply(mergers, getN),
  nonchim = rowSums(seqtab_nochim),
  perc_retained = rowSums(seqtab_nochim) / out[, 1] * 100
)

rownames(log_table) <- sample_names
```

On exporte ensuite cette table.

```{r}
df_export(log_table, new_rn = "sample") |>
  write.table(file = file.path(export, "log_table.tsv"),
              quote = FALSE,
              sep = "\t",
              row.names = FALSE)
```



Maintenant que toutes les séquences sont triées, on peut effectuer l'arbre de distance phylogénétique par la méthode du Neighbor Joining (Figure 2A).Il nous faut un package et une librairie.

```{r}
library(phangorn)
```


À partir des données de la partie 1, on fait une matrice de distance grâce aux séquences débruitées, déchimérisées et classées dans une table. Ensuite, on fait l'arbre de distance par NJ et on le visualise grâce à un plot.

```{r}
dist_matrix <- dist(seqtab_nochim, method = "hamming")
nj_tree <- nj(dist_matrix)
plot(nj_tree, show.tip.label = FALSE)
```


Ensuite, nous pouvons calculer l'abondance relative et l'alpha diversité (Figure 3A) grâce aux packages vegan et phyloseq.

```{r}
library(vegan)
library(phyloseq)
devtools::load_all(path="/home/rstudio/ADM2023_tutoriel/course-material-main/R")
```

On crée une matrice puis des tables de séquences et de taxonomie.

```{r}
seq_finales <- matrix(seqtab_nochim)
seq_table <- otu_table(as.matrix(seq_finales), taxa_are_rows = FALSE)
taxa_table <- tax_table(data.frame(Phylum = rep("Bacteria", 5)))
physeq <- phyloseq(seq_table, taxa_table)
```

À partir de là, on calcule l'alpha diversité et on l'affiche.

```{r}
alpha_diversity <- estimate_richness(physeq)
print(alpha_diversity)
```

Table d'abondance relative et on l'affiche

```{r}
abundance_table <- transform_sample_counts(physeq, function(x) x / sum(x))
print(abundance_table)
```

Maintenant, on peut tracer un histogramme à l'aide de la librarie ggplot2.

```{r}
library(ggplot2)
library(dplyr)
devtools::load_all(path="/home/rstudio/ADM2023_tutoriel/course-material-main/R")
```

```{r}
ggplot(data = alpha_diversity, aes(x = Observed)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black", alpha = 0.95) +
  labs(title = "Histogramme de la diversité alpha",
       x = "Richesse spécifique (Observed)",
       y = "Fréquence") +
  theme_minimal()
```

On peut tracer les diagrammes en boîtes associés (Figures 3B).

```{r}
ggplot(alpha_data, aes(x = seqtab_nochim, y = Observed)) +
  geom_boxplot(fill = "blue", color = "black", alpha = 0.95) +
  labs(title = "Observed Features",
       x = "Échantillon",
       y = "Richesse spécifique (Observed)") +
  theme_minimal()

ggplot(alpha_data, aes(x = seqtab_nochim, y = Shannon)) +
  geom_boxplot(fill = "green", color = "black", alpha = 0.95) +
  labs(title = "Entropie de Shannon",
       x = "Échantillons",
       y = "Entropie de Shannon") +
  theme_minimal()

ggplot(alpha_data, aes(x = seqtab_nochim, y = Faith_PD)) +
  geom_boxplot(fill = "orange", color = "black", alpha = 0.95) +
  labs(title = "Faith PD",
       x = "Échantillons",
       y = "Diversité phylogénétique (Faith PD)") +
  theme_minimal()
```

On peut maintenant réaliser la PCoA de Bray-Curtis et la tracer.

```{r}
bray_curtis_data <- matrix(seqtab_nochim)
pcoa_result <- pcoa(vegdist(bray_curtis_data, method = "bray"))
pcoa_coords <- scores(pcoa_result)
pcoa_df <- data.frame(Sample = rep(c("Sample1", "Sample2", "Sample3"), each = 100),
                      PC1 = pcoa_coords[, 1],
                      PC2 = pcoa_coords[, 2])


ggplot(pcoa_df, aes(x = PC1, y = PC2, color = Sample)) +
  geom_point(size = 3) +
  labs(title = "PCoA de Bray-Curtis",
       x = "PCoA1",
       y = "PCoA2") +
  theme_minimal()
```

On peut également faire la même chose avec la PCoA de Unifrac.

```{r}
otu_table <- matrix(seqtab_nochim)
sample_data <- data.frame(seqtab_nochim)
tax_table <- data.frame(Taxon = paste("OTU", 1:100, sep = ""))
physeq <- phyloseq(otu_table(otu_table, taxa_are_rows = TRUE),
                   sample_data(sample_data),
                   tax_table(tax_table))

pcoa_result <- ordinate(physeq, method = "wunifrac")
pcoa_coords <- scores(pcoa_result)
pcoa_df <- data.frame(Sample = rep(c(seqtab_nochim), each = 100),
                      PC1 = pcoa_coords[, 1],
                      PC2 = pcoa_coords[, 2])

ggplot(pcoa_df, aes(x = PC1, y = PC2, color = Sample)) +
  geom_point(size = 3) +
  labs(title = "Weighted Unifrac PCoA",
       x = "PCoA1",
       y = "PCoA2") +
  theme_minimal()
```


Maintenant, nous pouvons créer une heatmap (Figure 6).

```{r}
ggplot(pcoa_df, aes(x = seqtab_nochim, y = PC1, fill = PC2)) +
  geom_tile() +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(title = "Heatmap de PCoA Weighted Unifrac",
       x = "Échantillon",
       y = "PCoA1") +
  theme_minimal()
```

Enfin, nous pouvons tracer la matrice de corrélation de Spearman (Figure 7).

```{r}
cor_matrix <- cor(pcoa_df[, seqtab_nochim], method = "spearman")

ggplot(data = as.data.frame(cor_matrix), aes(x = Var1, y = Var2, fill = cor)) +
  geom_tile() +
  scale_fill_gradient2(low = "red", mid = "white", high = "blue", midpoint = 0) +
  labs(title = "Heatmap de Corrélation de Spearman",
       x = "Paramètres",
       y = "Paramètres") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

